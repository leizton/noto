{"lines":[{"id":"011713A8-A95F-497A-8EA2-65316562FC49","content":"word2vec\n","styles":[],"paragraphType":"title","attachments":[]},{"id":"67098488-7961-4526-8E2F-A2F41D310C11","content":"\n","styles":[],"attachments":[]},{"id":"23B9C53A-6661-42B9-BEE2-1FF56564555D","content":"### Ref\n","styles":[],"attachments":[]},{"id":"E119B44F-DEBA-42DC-B943-4036993F1C07","content":"Tomas Mikolov, Kai Chen, Greg Corrado, and Jeffrey Dean. Efficient Estimation of Word Representations in Vector Space. In Proceedings of Workshop at ICLR, 2013.\n","styles":[{"type":"italic","range":[0,161]},{"type":"underline","range":[57,117]}],"paragraphType":"body","attachments":[]},{"id":"F4E8BC29-A4DC-49CE-BA49-D04D227F1A41","content":"\n","styles":[],"attachments":[]},{"id":"9A67C507-8459-4032-86EF-3BEFD38CCBAE","content":"￼\n","styles":[{"type":"italic","range":[1,2]}],"paragraphType":"body","attachments":[{"percentageWidth":1,"content":"http:\/\/mccormickml.com\/2016\/04\/19\/word2vec-tutorial-the-skip-gram-model\/","type":"link","name":"6053CB29-F545-45D1-9CBF-8EF8BE5E9480","location":0}]},{"id":"87C60FF8-73F5-49D3-8701-FAB3EDB3D37F","content":"\n","styles":[],"attachments":[]},{"id":"E0A7141E-CFA2-4052-8104-4F7E28505768","content":"### Model Details\n","styles":[],"attachments":[]},{"id":"1F19F0F3-190C-4504-8684-205F2A4A84AF","content":"设有10000个单词需要做embedding，用skip-gram\n","styles":[],"attachments":[]},{"id":"8A209F14-2B0C-4E9C-85D2-DCD935FEFE3E","content":"输入是one-hot编码，输入层有10000个单元\n","styles":[],"attachments":[]},{"id":"DA970258-4277-4651-B470-1DB5BEF24B4D","content":"输出层有10000个单元，每个单元表示其对应的单词是输入词的上下文的概率\n","styles":[],"attachments":[]},{"id":"2B392EC9-DB00-4EB8-8884-C5AA968520B6","content":"隐层有300个单元，每个单元没有激活函数\n","styles":[],"attachments":[]},{"id":"3BC1A43A-A909-41B0-A07F-D30B74B332A4","content":"##### Architecture of the neural network\n","styles":[],"attachments":[]},{"id":"7A628D30-3EF9-46BF-A134-AD946A7F8E3D","content":"￼\n","styles":[],"paragraphType":"body","attachments":[{"percentageWidth":0.64000000000000001,"type":"image","name":"arch_of_network.jpg","location":0}]},{"id":"D5631D64-3EA0-4A72-A539-80901E6D7461","content":"##### Result\n","styles":[],"attachments":[]},{"id":"A235141E-96DF-45C7-9DAD-E7EAC4567EAF","content":"每个输入单元和隐层间有300个权重，这300个权重就是最终学习到的单词的特征\n","styles":[],"attachments":[]},{"id":"C584F5A0-134E-498F-9B9A-3AD634AE9796","content":"\n","styles":[],"attachments":[]},{"id":"C328C689-836F-4EF2-9CD6-FE07F454A72F","content":"### 计算相似度(上下文概率)\n","styles":[],"attachments":[]},{"id":"074C3A63-8007-4AAE-AC03-0D14DDC9A6B4","content":"两个单词的特征向量相乘，并用softmax做归一化\n","styles":[],"attachments":[]},{"id":"7A628D30-3EC9-46BF-A134-CC946A7F8E3D","content":"￼\n","styles":[],"paragraphType":"body","attachments":[{"percentageWidth":0.64000000000000001,"type":"image","name":"calc_words_sim.jpg","location":0}]},{"id":"0FF12143-6700-4C6C-BA2D-4F17CE1D46B6","content":"\n","styles":[],"attachments":[]},{"id":"83AF3E11-A075-4F11-91A2-73951F638433","content":"","styles":[],"attachments":[]}]}